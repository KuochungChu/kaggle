{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xgboost gpu 支持\n",
    "```\n",
    "git clone --recursive https://github.com/dmlc/xgboost\n",
    "mkdir build\n",
    "cd build\n",
    "cmake .. -DUSE_CUDA=ON\n",
    "make -j\n",
    "```\n",
    "具体可以查看：https://xgboost.readthedocs.io/en/latest/build.html#building-with-gpu-support\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '/mnt/wc/anaconda3/envs/fastai/lib/python36.zip',\n",
       " '/mnt/wc/anaconda3/envs/fastai/lib/python3.6',\n",
       " '/mnt/wc/anaconda3/envs/fastai/lib/python3.6/lib-dynload',\n",
       " '/mnt/wc/anaconda3/envs/fastai/lib/python3.6/site-packages',\n",
       " '/mnt/wc/anaconda3/envs/fastai/lib/python3.6/site-packages/IPython/extensions',\n",
       " '/root/.ipython',\n",
       " '/mnt/wc/xgboost/python-package']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/mnt/wc/xgboost/python-package')\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.rand(40000,200))\n",
    "y = df.iloc[:,-1]\n",
    "df = df.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 59.3 s, sys: 52 ms, total: 59.3 s\n",
      "Wall time: 59.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Without using the GPUs: \n",
    "m_cpu = xgb.XGBRegressor()\n",
    "%time m_cpu.fit(df,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.73 s, sys: 580 ms, total: 3.31 s\n",
      "Wall time: 1.91 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=-1, nthread=None, objective='reg:linear',\n",
       "       predictor='gpu_predictor', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,\n",
       "       subsample=1, tree_method='gpu_hist')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using the GPUs: \n",
    "gpu_params = {'tree_method':'gpu_hist', \n",
    "              'predictor':'gpu_predictor',\n",
    "              'n_jobs': -1}\n",
    "\n",
    "m_gpu = xgb.XGBRegressor(**gpu_params)\n",
    "%time m_gpu.fit(df,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.037861668371099944"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_gpu.score(df,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## boosting算法\n",
    "关于boosting算法，之前写过一篇文章 [boosting原理](https://www.zybuluo.com/zhuanxu/note/970185)，里面的涉及的数学推导会比较多，想看数学原理的可以去查看。\n",
    "\n",
    "第一个boosting算法：AdaBoost，然后Friedman将AdaBoost推广到一般Gradient Boosting框架，得到Gradient Boosting Machines (GBM): 将boosting视作一个数值优化问题，采用类似梯度下降的方式优化求解。\n",
    "\n",
    "另外关于boost和bag可以看下面图：\n",
    "![](http://static.zybuluo.com/zhuanxu/3lryqzm33fi8i6maz3tmwebc/image_1c9ot34k5ec6okq12fu85i1nji9.png)\n",
    "其中boost产生了GBDT，bag产生了随机森林"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 简单例子：毒蘑菇\n",
    "可以看 [1-1 基本模型调用.ipynb](https://www.zybuluo.com/zhuanxu/note/969884)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 显示图片\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
