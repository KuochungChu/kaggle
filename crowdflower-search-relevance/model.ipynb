{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import csv\n",
    "import os\n",
    "## hyperopt\n",
    "# from hyperopt import hp\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "from sklearn.datasets import load_svmlight_file, dump_svmlight_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_model(models, feat_name):\n",
    "    if models == \"all\":\n",
    "        return True\n",
    "    for model in models:\n",
    "        if model in feat_name:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## xgboost\n",
    "xgb_random_seed = 2017\n",
    "xgb_nthread = 2\n",
    "xgb_dmatrix_silent = True\n",
    "\n",
    "## sklearn\n",
    "skl_random_seed = 2017\n",
    "skl_n_jobs = 2\n",
    "\n",
    "xgb_min_num_round = 10\n",
    "xgb_max_num_round = 500\n",
    "xgb_num_round_step = 10\n",
    "skl_min_n_estimators = 10\n",
    "skl_max_n_estimators = 500\n",
    "skl_n_estimators_step = 10\n",
    "libfm_min_iter = 10\n",
    "libfm_max_iter = 500\n",
    "iter_step = 10\n",
    "hyperopt_param = {}\n",
    "hyperopt_param[\"xgb_max_evals\"] = 200\n",
    "hyperopt_param[\"rf_max_evals\"] = 200\n",
    "hyperopt_param[\"etr_max_evals\"] = 200\n",
    "hyperopt_param[\"gbm_max_evals\"] = 200\n",
    "hyperopt_param[\"lr_max_evals\"] = 200\n",
    "hyperopt_param[\"ridge_max_evals\"] = 200\n",
    "hyperopt_param[\"lasso_max_evals\"] = 200\n",
    "hyperopt_param['svr_max_evals'] = 200\n",
    "hyperopt_param['dnn_max_evals'] = 200\n",
    "hyperopt_param['libfm_max_evals'] = 200\n",
    "hyperopt_param['rgf_max_evals'] = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"../../Output\"\n",
    "log_path = \"%s/Log\" % output_path\n",
    "if not os.path.exists(log_path):\n",
    "    os.makedirs(log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "specified_models = \"[Pre@solution]_[Feat@svd100_and_bow_Jun27]_[Model@reg_xgb_linear]\"\n",
    "## regression with linear booster\n",
    "param_space_reg_xgb_linear = {\n",
    "    'task': 'regression',\n",
    "    'booster': 'gblinear',\n",
    "    'objective': 'reg:linear',\n",
    "    'eta' : hp.quniform('eta', 0.01, 1, 0.01),\n",
    "    'lambda' : hp.quniform('lambda', 0, 5, 0.05),\n",
    "    'alpha' : hp.quniform('alpha', 0, 0.5, 0.005),\n",
    "    'lambda_bias' : hp.quniform('lambda_bias', 0, 3, 0.1),\n",
    "    'num_round' : hp.quniform('num_round', xgb_min_num_round, xgb_max_num_round, xgb_num_round_step),\n",
    "    'nthread': xgb_nthread,\n",
    "    'silent' : 1,\n",
    "    'seed': xgb_random_seed,\n",
    "    \"max_evals\": hyperopt_param[\"xgb_max_evals\"],\n",
    "}\n",
    "param_space = param_space_reg_xgb_linear\n",
    "feat_name = specified_models\n",
    "feat_folder = \"../data/crowdflower-search-relevance/Feat/solution/svd100_and_bow_Jun27\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file = \"%s/%s_hyperopt.log\" % (log_path, feat_name)\n",
    "log_handler = open( log_file, 'w' )\n",
    "writer = csv.writer(log_handler)\n",
    "headers = [ 'trial_counter', 'kappa_mean', 'kappa_std' ]\n",
    "for k,v in sorted(param_space.items()):\n",
    "    headers.append(k)\n",
    "writer.writerow(headers)\n",
    "log_handler.flush()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "\n",
    "### global params\n",
    "## you can use bagging to stabilize the predictions\n",
    "bootstrap_ratio = 1\n",
    "bootstrap_replacement = False\n",
    "bagging_size= 1\n",
    "\n",
    "ebc_hard_threshold = False\n",
    "verbose_level = 1\n",
    "\n",
    "\n",
    "#### train CV and final model with a specified parameter setting\n",
    "def hyperopt_obj(param, feat_folder, feat_name, trial_counter):\n",
    "    n_runs = 3\n",
    "    n_folds = 3\n",
    "    kappa_cv = np.zeros((n_runs, n_folds), dtype=float)\n",
    "    for run in range(1,n_runs+1):\n",
    "        for fold in range(1,n_folds+1):\n",
    "            rng = np.random.RandomState(2017 + 1000 * run + 10 * fold)\n",
    "            #### all the path\n",
    "            path = \"%s/Run%d/Fold%d\" % (feat_folder, run, fold)\n",
    "            save_path = \"%s/Run%d/Fold%d\" % (output_path, run, fold)\n",
    "            if not os.path.exists(save_path):\n",
    "                os.makedirs(save_path)\n",
    "            # feat\n",
    "            feat_train_path = \"%s/train.feat\" % path\n",
    "            feat_valid_path = \"%s/valid.feat\" % path\n",
    "            # weight\n",
    "            weight_train_path = \"%s/train.feat.weight\" % path\n",
    "            weight_valid_path = \"%s/valid.feat.weight\" % path\n",
    "            # info\n",
    "            info_train_path = \"%s/train.info\" % path\n",
    "            info_valid_path = \"%s/valid.info\" % path\n",
    "            # cdf\n",
    "            cdf_valid_path = \"%s/valid.cdf\" % path\n",
    "            # raw prediction path (rank)\n",
    "            raw_pred_valid_path = \"%s/valid.raw.pred.%s_[Id@%d].csv\" % (save_path, feat_name, trial_counter)\n",
    "            rank_pred_valid_path = \"%s/valid.pred.%s_[Id@%d].csv\" % (save_path, feat_name, trial_counter)\n",
    "            ## load feat\n",
    "            X_train, labels_train = load_svmlight_file(feat_train_path)\n",
    "            X_valid, labels_valid = load_svmlight_file(feat_valid_path)\n",
    "            if X_valid.shape[1] < X_train.shape[1]:\n",
    "                X_valid = hstack([X_valid, np.zeros((X_valid.shape[0], X_train.shape[1]-X_valid.shape[1]))])\n",
    "            elif X_valid.shape[1] > X_train.shape[1]:\n",
    "                X_train = hstack([X_train, np.zeros((X_train.shape[0], X_valid.shape[1]-X_train.shape[1]))])\n",
    "            X_train = X_train.tocsr()\n",
    "            X_valid = X_valid.tocsr()\n",
    "            ## load weight\n",
    "            weight_train = np.loadtxt(weight_train_path, dtype=float)\n",
    "            weight_valid = np.loadtxt(weight_valid_path, dtype=float)\n",
    "\n",
    "            ## load valid info\n",
    "            info_train = pd.read_csv(info_train_path)\n",
    "            numTrain = info_train.shape[0]\n",
    "            info_valid = pd.read_csv(info_valid_path)\n",
    "            numValid = info_valid.shape[0]\n",
    "            Y_valid = info_valid[\"median_relevance\"]\n",
    "            ## load cdf\n",
    "            cdf_valid = np.loadtxt(cdf_valid_path, dtype=float)\n",
    "            ## make evalerror func\n",
    "            evalerror_regrank_valid = lambda preds,dtrain: evalerror_regrank_cdf(preds, dtrain, cdf_valid)\n",
    "            evalerror_softmax_valid = lambda preds,dtrain: evalerror_softmax_cdf(preds, dtrain, cdf_valid)\n",
    "            evalerror_softkappa_valid = lambda preds,dtrain: evalerror_softkappa_cdf(preds, dtrain, cdf_valid)\n",
    "            evalerror_ebc_valid = lambda preds,dtrain: evalerror_ebc_cdf(preds, dtrain, cdf_valid, ebc_hard_threshold)\n",
    "            evalerror_cocr_valid = lambda preds,dtrain: evalerror_cocr_cdf(preds, dtrain, cdf_valid)\n",
    "            ##############\n",
    "            ## Training ##\n",
    "            ##############\n",
    "            ## you can use bagging to stabilize the predictions\n",
    "            preds_bagging = np.zeros((numValid, bagging_size), dtype=float)\n",
    "            for n in range(bagging_size):\n",
    "                if bootstrap_replacement:\n",
    "                    sampleSize = int(numTrain*bootstrap_ratio)\n",
    "                    index_base = rng.randint(numTrain, size=sampleSize)\n",
    "                    index_meta = [i for i in range(numTrain) if i not in index_base]\n",
    "                else:\n",
    "                    randnum = rng.uniform(size=numTrain)\n",
    "                    index_base = [i for i in range(numTrain) if randnum[i] < bootstrap_ratio]\n",
    "                    index_meta = [i for i in range(numTrain) if randnum[i] >= bootstrap_ratio]\n",
    "                if \"booster\" in param:\n",
    "                    dvalid_base = xgb.DMatrix(X_valid, label=labels_valid, weight=weight_valid)\n",
    "                    dtrain_base = xgb.DMatrix(X_train[index_base], label=labels_train[index_base], weight=weight_train[index_base])\n",
    "                        \n",
    "                    watchlist = []\n",
    "                    if verbose_level >= 2:\n",
    "                        watchlist  = [(dtrain_base, 'train'), (dvalid_base, 'valid')]\n",
    "                ## regression & pairwise ranking with xgboost\n",
    "                bst = xgb.train(param, dtrain_base, param['num_round'], watchlist, feval=evalerror_regrank_valid)\n",
    "                pred = bst.predict(dvalid_base) \n",
    "                ## weighted averageing over different models\n",
    "                pred_valid = pred\n",
    "                ## this bagging iteration\n",
    "                preds_bagging[:,n] = pred_valid\n",
    "                pred_raw = np.mean(preds_bagging[:,:(n+1)], axis=1)\n",
    "                pred_rank = pred_raw.argsort().argsort()\n",
    "                pred_score, cutoff = getScore(pred_rank, cdf_valid, valid=True)\n",
    "                kappa_valid = quadratic_weighted_kappa(pred_score, Y_valid)\n",
    "                if (n+1) != bagging_size:\n",
    "                    print(\"              {:>3}   {:>3}   {:>3}   {:>6}   {} x {}\".format(\n",
    "                                run, fold, n+1, np.round(kappa_valid,6), X_train.shape[0], X_train.shape[1]))\n",
    "                else:\n",
    "                    print(\"                    {:>3}       {:>3}      {:>3}    {:>8}  {} x {}\".format(\n",
    "                                run, fold, n+1, np.round(kappa_valid,6), X_train.shape[0], X_train.shape[1]))\n",
    "            kappa_cv[run-1,fold-1] = kappa_valid\n",
    "            ## save this prediction\n",
    "            dfPred = pd.DataFrame({\"target\": Y_valid, \"prediction\": pred_raw})\n",
    "            dfPred.to_csv(raw_pred_valid_path, index=False, header=True,\n",
    "                         columns=[\"target\", \"prediction\"])\n",
    "            ## save this prediction\n",
    "            dfPred = pd.DataFrame({\"target\": Y_valid, \"prediction\": pred_rank})\n",
    "            dfPred.to_csv(rank_pred_valid_path, index=False, header=True,\n",
    "                         columns=[\"target\", \"prediction\"])\n",
    "    kappa_cv_mean = np.mean(kappa_cv)\n",
    "    kappa_cv_std = np.std(kappa_cv)\n",
    "    if verbose_level >= 1:\n",
    "        print(\"              Mean: %.6f\" % kappa_cv_mean)\n",
    "        print(\"              Std: %.6f\" % kappa_cv_std)\n",
    "    ####################\n",
    "    #### Retraining ####\n",
    "    ####################\n",
    "    #### all the path\n",
    "    path = \"%s/All\" % (feat_folder)\n",
    "    save_path = \"%s/All\" % output_path\n",
    "    subm_path = \"%s/Subm\" % output_path\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    if not os.path.exists(subm_path):\n",
    "        os.makedirs(subm_path)\n",
    "    # feat\n",
    "    feat_train_path = \"%s/train.feat\" % path\n",
    "    feat_test_path = \"%s/test.feat\" % path\n",
    "    # weight\n",
    "    weight_train_path = \"%s/train.feat.weight\" % path\n",
    "    # info\n",
    "    info_train_path = \"%s/train.info\" % path\n",
    "    info_test_path = \"%s/test.info\" % path\n",
    "    # cdf\n",
    "    cdf_test_path = \"%s/test.cdf\" % path\n",
    "    # raw prediction path (rank)\n",
    "    raw_pred_test_path = \"%s/test.raw.pred.%s_[Id@%d].csv\" % (save_path, feat_name, trial_counter)\n",
    "    rank_pred_test_path = \"%s/test.pred.%s_[Id@%d].csv\" % (save_path, feat_name, trial_counter)\n",
    "    # submission path (relevance as in [1,2,3,4])\n",
    "    subm_path = \"%s/test.pred.%s_[Id@%d]_[Mean%.6f]_[Std%.6f].csv\" % (subm_path, feat_name, trial_counter, kappa_cv_mean, kappa_cv_std)\n",
    "\n",
    "    #### load data\n",
    "    ## load feat\n",
    "    X_train, labels_train = load_svmlight_file(feat_train_path)\n",
    "    X_test, labels_test = load_svmlight_file(feat_test_path)\n",
    "    if X_test.shape[1] < X_train.shape[1]:\n",
    "        X_test = hstack([X_test, np.zeros((X_test.shape[0], X_train.shape[1]-X_test.shape[1]))])\n",
    "    elif X_test.shape[1] > X_train.shape[1]:\n",
    "        X_train = hstack([X_train, np.zeros((X_train.shape[0], X_test.shape[1]-X_train.shape[1]))])\n",
    "    X_train = X_train.tocsr()\n",
    "    X_test = X_test.tocsr()\n",
    "    ## load train weight\n",
    "    weight_train = np.loadtxt(weight_train_path, dtype=float)\n",
    "    ## load test info\n",
    "    info_train = pd.read_csv(info_train_path)\n",
    "    numTrain = info_train.shape[0]\n",
    "    info_test = pd.read_csv(info_test_path)\n",
    "    numTest = info_test.shape[0]\n",
    "    id_test = info_test[\"id\"]\n",
    "    \n",
    "    ## load cdf\n",
    "    cdf_test = np.loadtxt(cdf_test_path, dtype=float)  \n",
    "    ##\n",
    "    evalerror_regrank_test = lambda preds,dtrain: evalerror_regrank_cdf(preds, dtrain, cdf_test)\n",
    "    evalerror_softmax_test = lambda preds,dtrain: evalerror_softmax_cdf(preds, dtrain, cdf_test)\n",
    "    evalerror_softkappa_test = lambda preds,dtrain: evalerror_softkappa_cdf(preds, dtrain, cdf_test)\n",
    "    evalerror_ebc_test = lambda preds,dtrain: evalerror_ebc_cdf(preds, dtrain, cdf_test, ebc_hard_threshold)\n",
    "    evalerror_cocr_test = lambda preds,dtrain: evalerror_cocr_cdf(preds, dtrain, cdf_test)\n",
    "\n",
    "    ## bagging\n",
    "    preds_bagging = np.zeros((numTest, bagging_size), dtype=float)\n",
    "    for n in range(bagging_size):\n",
    "        if bootstrap_replacement:\n",
    "            sampleSize = int(numTrain*bootstrap_ratio)\n",
    "            #index_meta = rng.randint(numTrain, size=sampleSize)\n",
    "            #index_base = [i for i in range(numTrain) if i not in index_meta]\n",
    "            index_base = rng.randint(numTrain, size=sampleSize)\n",
    "            index_meta = [i for i in range(numTrain) if i not in index_base]\n",
    "        else:\n",
    "            randnum = rng.uniform(size=numTrain)\n",
    "            index_base = [i for i in range(numTrain) if randnum[i] < bootstrap_ratio]\n",
    "            index_meta = [i for i in range(numTrain) if randnum[i] >= bootstrap_ratio]\n",
    " \n",
    "        if \"booster\" in param:\n",
    "            dtest = xgb.DMatrix(X_test, label=labels_test)\n",
    "            dtrain = xgb.DMatrix(X_train[index_base], label=labels_train[index_base], weight=weight_train[index_base])\n",
    "                \n",
    "            watchlist = []\n",
    "            if verbose_level >= 2:\n",
    "                watchlist  = [(dtrain, 'train')]\n",
    "        bst = xgb.train(param, dtrain, param['num_round'], watchlist, feval=evalerror_regrank_test)\n",
    "        pred = bst.predict(dtest)\n",
    "        \n",
    "        ## weighted averageing over different models\n",
    "        pred_test = pred\n",
    "        preds_bagging[:,n] = pred_test\n",
    "    pred_raw = np.mean(preds_bagging, axis=1)\n",
    "    pred_rank = pred_raw.argsort().argsort()\n",
    "    #\n",
    "    ## write\n",
    "    output = pd.DataFrame({\"id\": id_test, \"prediction\": pred_raw})    \n",
    "    output.to_csv(raw_pred_test_path, index=False)\n",
    "\n",
    "    ## write\n",
    "    output = pd.DataFrame({\"id\": id_test, \"prediction\": pred_rank})    \n",
    "    output.to_csv(rank_pred_test_path, index=False)\n",
    "\n",
    "    ## write score\n",
    "    pred_score = getScore(pred, cdf_test)\n",
    "    output = pd.DataFrame({\"id\": id_test, \"prediction\": pred_score})    \n",
    "    output.to_csv(subm_path, index=False)\n",
    "    #\"\"\"\n",
    "        \n",
    "    return kappa_cv_mean, kappa_cv_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## integer features\n",
    "int_feat = [\"num_round\", \"n_estimators\", \"max_depth\", \"degree\",\n",
    "            \"hidden_units\", \"hidden_layers\", \"batch_size\", \"nb_epoch\",\n",
    "            \"dim\", \"iter\",\n",
    "            \"max_leaf_forest\", \"num_iteration_opt\", \"num_tree_search\", \"min_pop\", \"opt_interval\"]\n",
    "\n",
    "def hyperopt_wrapper(param, feat_folder, feat_name):\n",
    "    global trial_counter\n",
    "    global log_handler\n",
    "    trial_counter += 1\n",
    "\n",
    "    # convert integer feat\n",
    "    for f in int_feat:\n",
    "        if f in param:\n",
    "            param[f] = int(param[f])\n",
    "\n",
    "    print(\"------------------------------------------------------------\")\n",
    "    print(\"Trial %d\" % trial_counter)\n",
    "\n",
    "    print(\"        Model\")\n",
    "    print(\"              %s\" % feat_name)\n",
    "    print(\"        Param\")\n",
    "    for k,v in sorted(param.items()):\n",
    "        print(\"              %s: %s\" % (k,v))\n",
    "    print(\"        Result\")\n",
    "    print(\"                    Run      Fold      Bag      Kappa      Shape\")\n",
    "\n",
    "    ## evaluate performance\n",
    "    ## 关键是这一步骤\n",
    "    kappa_cv_mean, kappa_cv_std = hyperopt_obj(param, feat_folder, feat_name, trial_counter)\n",
    "\n",
    "    ## log\n",
    "    var_to_log = [\n",
    "        \"%d\" % trial_counter,\n",
    "        \"%.6f\" % kappa_cv_mean, \n",
    "        \"%.6f\" % kappa_cv_std\n",
    "    ]\n",
    "    for k,v in sorted(param.items()):\n",
    "        var_to_log.append(\"%s\" % v)\n",
    "    writer.writerow(var_to_log)\n",
    "    log_handler.flush()\n",
    "\n",
    "    return {'loss': -kappa_cv_mean, 'attachments': {'std': kappa_cv_std}, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************\n",
      "Search for the best params\n",
      "------------------------------------------------------------\n",
      "Trial 1\n",
      "        Model\n",
      "              [Pre@solution]_[Feat@svd100_and_bow_Jun27]_[Model@reg_xgb_linear]\n",
      "        Param\n",
      "              alpha: 0.21\n",
      "              booster: gblinear\n",
      "              eta: 0.06\n",
      "              lambda: 4.7\n",
      "              lambda_bias: 0.2\n",
      "              max_evals: 200\n",
      "              nthread: 2\n",
      "              num_round: 230\n",
      "              objective: reg:linear\n",
      "              seed: 2017\n",
      "              silent: 1\n",
      "              task: regression\n",
      "        Result\n",
      "                    Run      Fold      Bag      Kappa      Shape\n",
      "                      1         1        1     0.67035  3470 x 124790\n",
      "                      1         2        1    0.665376  3393 x 125458\n",
      "                      1         3        1    0.660125  3295 x 115835\n",
      "                      2         1        1    0.660489  3470 x 126995\n",
      "                      2         2        1    0.678318  3393 x 119863\n",
      "                      2         3        1    0.669738  3295 x 116069\n",
      "                      3         1        1    0.671777  3470 x 125768\n",
      "                      3         2        1    0.669473  3393 x 121161\n",
      "                      3         3        1     0.66124  3295 x 116847\n",
      "              Mean: 0.667432\n",
      "              Std: 0.005769\n",
      "------------------------------------------------------------\n",
      "Trial 2\n",
      "        Model\n",
      "              [Pre@solution]_[Feat@svd100_and_bow_Jun27]_[Model@reg_xgb_linear]\n",
      "        Param\n",
      "              alpha: 0.47500000000000003\n",
      "              booster: gblinear\n",
      "              eta: 0.36\n",
      "              lambda: 4.05\n",
      "              lambda_bias: 0.2\n",
      "              max_evals: 200\n",
      "              nthread: 2\n",
      "              num_round: 420\n",
      "              objective: reg:linear\n",
      "              seed: 2017\n",
      "              silent: 1\n",
      "              task: regression\n",
      "        Result\n",
      "                    Run      Fold      Bag      Kappa      Shape\n",
      "                      1         1        1    0.662403  3470 x 124790\n",
      "                      1         2        1      0.6559  3393 x 125458\n",
      "                      1         3        1    0.650678  3295 x 115835\n",
      "                      2         1        1    0.657218  3470 x 126995\n",
      "                      2         2        1    0.668347  3393 x 119863\n",
      "                      2         3        1    0.655312  3295 x 116069\n",
      "                      3         1        1    0.663985  3470 x 125768\n",
      "                      3         2        1    0.661603  3393 x 121161\n",
      "                      3         3        1    0.646311  3295 x 116847\n",
      "              Mean: 0.657973\n",
      "              Std: 0.006478\n",
      "------------------------------------------------------------\n",
      "Trial 3\n",
      "        Model\n",
      "              [Pre@solution]_[Feat@svd100_and_bow_Jun27]_[Model@reg_xgb_linear]\n",
      "        Param\n",
      "              alpha: 0.5\n",
      "              booster: gblinear\n",
      "              eta: 0.23\n",
      "              lambda: 4.800000000000001\n",
      "              lambda_bias: 0.0\n",
      "              max_evals: 200\n",
      "              nthread: 2\n",
      "              num_round: 50\n",
      "              objective: reg:linear\n",
      "              seed: 2017\n",
      "              silent: 1\n",
      "              task: regression\n",
      "        Result\n",
      "                    Run      Fold      Bag      Kappa      Shape\n",
      "                      1         1        1     0.65617  3470 x 124790\n",
      "                      1         2        1    0.656053  3393 x 125458\n",
      "                      1         3        1    0.642906  3295 x 115835\n",
      "                      2         1        1    0.655037  3470 x 126995\n",
      "                      2         2        1    0.666966  3393 x 119863\n",
      "                      2         3        1    0.643924  3295 x 116069\n",
      "                      3         1        1    0.659932  3470 x 125768\n",
      "                      3         2        1    0.656665  3393 x 121161\n",
      "                      3         3        1    0.644954  3295 x 116847\n",
      "              Mean: 0.653623\n",
      "              Std: 0.007642\n",
      "------------------------------------------------------------\n",
      "Trial 4\n",
      "        Model\n",
      "              [Pre@solution]_[Feat@svd100_and_bow_Jun27]_[Model@reg_xgb_linear]\n",
      "        Param\n",
      "              alpha: 0.375\n",
      "              booster: gblinear\n",
      "              eta: 0.88\n",
      "              lambda: 3.25\n",
      "              lambda_bias: 2.8000000000000003\n",
      "              max_evals: 200\n",
      "              nthread: 2\n",
      "              num_round: 180\n",
      "              objective: reg:linear\n",
      "              seed: 2017\n",
      "              silent: 1\n",
      "              task: regression\n",
      "        Result\n",
      "                    Run      Fold      Bag      Kappa      Shape\n",
      "                      1         1        1    0.667389  3470 x 124790\n",
      "                      1         2        1     0.66293  3393 x 125458\n",
      "                      1         3        1    0.657839  3295 x 115835\n",
      "                      2         1        1    0.663605  3470 x 126995\n",
      "                      2         2        1    0.676324  3393 x 119863\n",
      "                      2         3        1    0.667308  3295 x 116069\n",
      "                      3         1        1    0.669283  3470 x 125768\n",
      "                      3         2        1    0.669782  3393 x 121161\n",
      "                      3         3        1    0.652795  3295 x 116847\n",
      "              Mean: 0.665251\n",
      "              Std: 0.006552\n",
      "------------------------------------------------------------\n",
      "Trial 5\n",
      "        Model\n",
      "              [Pre@solution]_[Feat@svd100_and_bow_Jun27]_[Model@reg_xgb_linear]\n",
      "        Param\n",
      "              alpha: 0.24\n",
      "              booster: gblinear\n",
      "              eta: 0.96\n",
      "              lambda: 2.5\n",
      "              lambda_bias: 0.30000000000000004\n",
      "              max_evals: 200\n",
      "              nthread: 2\n",
      "              num_round: 80\n",
      "              objective: reg:linear\n",
      "              seed: 2017\n",
      "              silent: 1\n",
      "              task: regression\n",
      "        Result\n",
      "                    Run      Fold      Bag      Kappa      Shape\n",
      "                      1         1        1    0.676115  3470 x 124790\n",
      "                      1         2        1     0.67103  3393 x 125458\n",
      "                      1         3        1     0.66241  3295 x 115835\n",
      "                      2         1        1    0.665941  3470 x 126995\n",
      "                      2         2        1    0.680772  3393 x 119863\n",
      "                      2         3        1    0.668219  3295 x 116069\n",
      "                      3         1        1    0.674115  3470 x 125768\n",
      "                      3         2        1    0.673022  3393 x 121161\n",
      "                      3         3        1    0.662446  3295 x 116847\n",
      "              Mean: 0.670452\n",
      "              Std: 0.005898\n",
      "------------------------------------------------------------\n",
      "Trial 6\n",
      "        Model\n",
      "              [Pre@solution]_[Feat@svd100_and_bow_Jun27]_[Model@reg_xgb_linear]\n",
      "        Param\n",
      "              alpha: 0.085\n",
      "              booster: gblinear\n",
      "              eta: 0.39\n",
      "              lambda: 1.55\n",
      "              lambda_bias: 0.2\n",
      "              max_evals: 200\n",
      "              nthread: 2\n",
      "              num_round: 80\n",
      "              objective: reg:linear\n",
      "              seed: 2017\n",
      "              silent: 1\n",
      "              task: regression\n",
      "        Result\n",
      "                    Run      Fold      Bag      Kappa      Shape\n",
      "                      1         1        1    0.677518  3470 x 124790\n",
      "                      1         2        1    0.661096  3393 x 125458\n",
      "                      1         3        1    0.668506  3295 x 115835\n",
      "                      2         1        1     0.66267  3470 x 126995\n",
      "                      2         2        1    0.681539  3393 x 119863\n",
      "                      2         3        1    0.674293  3295 x 116069\n",
      "                      3         1        1    0.675673  3470 x 125768\n",
      "                      3         2        1    0.669164  3393 x 121161\n",
      "                      3         3        1    0.662295  3295 x 116847\n",
      "              Mean: 0.670306\n",
      "              Std: 0.006950\n",
      "------------------------------------------------------------\n",
      "Trial 7\n",
      "        Model\n",
      "              [Pre@solution]_[Feat@svd100_and_bow_Jun27]_[Model@reg_xgb_linear]\n",
      "        Param\n",
      "              alpha: 0.325\n",
      "              booster: gblinear\n",
      "              eta: 0.68\n",
      "              lambda: 1.9500000000000002\n",
      "              lambda_bias: 2.2\n",
      "              max_evals: 200\n",
      "              nthread: 2\n",
      "              num_round: 70\n",
      "              objective: reg:linear\n",
      "              seed: 2017\n",
      "              silent: 1\n",
      "              task: regression\n",
      "        Result\n",
      "                    Run      Fold      Bag      Kappa      Shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      1         1        1    0.672687  3470 x 124790\n",
      "                      1         2        1    0.666445  3393 x 125458\n",
      "                      1         3        1    0.660734  3295 x 115835\n",
      "                      2         1        1    0.666876  3470 x 126995\n",
      "                      2         2        1    0.678471  3393 x 119863\n",
      "                      2         3        1    0.666245  3295 x 116069\n",
      "                      3         1        1    0.671777  3470 x 125768\n",
      "                      3         2        1    0.672868  3393 x 121161\n",
      "                      3         3        1    0.658525  3295 x 116847\n",
      "              Mean: 0.668292\n",
      "              Std: 0.005945\n",
      "------------------------------------------------------------\n",
      "Trial 12\n",
      "        Model\n",
      "              [Pre@solution]_[Feat@svd100_and_bow_Jun27]_[Model@reg_xgb_linear]\n",
      "        Param\n",
      "              alpha: 0.385\n",
      "              booster: gblinear\n",
      "              eta: 0.34\n",
      "              lambda: 1.4000000000000001\n",
      "              lambda_bias: 0.2\n",
      "              max_evals: 200\n",
      "              nthread: 2\n",
      "              num_round: 280\n",
      "              objective: reg:linear\n",
      "              seed: 2017\n",
      "              silent: 1\n",
      "              task: regression\n",
      "        Result\n",
      "                    Run      Fold      Bag      Kappa      Shape\n",
      "                      1         1        1    0.672687  3470 x 124790\n",
      "                      1         2        1    0.669044  3393 x 125458\n",
      "                      1         3        1    0.661039  3295 x 115835\n",
      "                      2         1        1    0.667499  3470 x 126995\n",
      "------------------------------------------------------------\n",
      "Trial 13\n",
      "        Model\n",
      "              [Pre@solution]_[Feat@svd100_and_bow_Jun27]_[Model@reg_xgb_linear]\n",
      "        Param\n",
      "              alpha: 0.325\n",
      "              booster: gblinear\n",
      "              eta: 0.04\n",
      "              lambda: 0.25\n",
      "              lambda_bias: 2.7\n",
      "              max_evals: 200\n",
      "              nthread: 2\n",
      "              num_round: 160\n",
      "              objective: reg:linear\n",
      "              seed: 2017\n",
      "              silent: 1\n",
      "              task: regression\n",
      "        Result\n",
      "                    Run      Fold      Bag      Kappa      Shape\n",
      "                      1         1        1    0.667545  3470 x 124790\n",
      "                      1         2        1    0.652079  3393 x 125458\n",
      "                      1         3        1    0.655249  3295 x 115835\n",
      "                      2         1        1    0.659087  3470 x 126995\n",
      "                      2         2        1    0.672949  3393 x 119863\n",
      "                      2         3        1    0.667612  3295 x 116069\n",
      "                      3         1        1    0.660244  3470 x 125768\n",
      "                      3         2        1    0.670399  3393 x 121161\n",
      "                      3         3        1    0.662898  3295 x 116847\n",
      "              Mean: 0.663118\n",
      "              Std: 0.006648\n",
      "------------------------------------------------------------\n",
      "Trial 14\n",
      "        Model\n",
      "              [Pre@solution]_[Feat@svd100_and_bow_Jun27]_[Model@reg_xgb_linear]\n",
      "        Param\n",
      "              alpha: 0.095\n",
      "              booster: gblinear\n",
      "              eta: 0.05\n",
      "              lambda: 1.6500000000000001\n",
      "              lambda_bias: 0.1\n",
      "              max_evals: 200\n",
      "              nthread: 2\n",
      "              num_round: 330\n",
      "              objective: reg:linear\n",
      "              seed: 2017\n",
      "              silent: 1\n",
      "              task: regression\n",
      "        Result\n",
      "                    Run      Fold      Bag      Kappa      Shape\n",
      "                      1         1        1    0.682348  3470 x 124790\n",
      "                      1         2        1    0.667362  3393 x 125458\n",
      "                      1         3        1     0.66622  3295 x 115835\n",
      "                      2         1        1    0.670147  3470 x 126995\n",
      "                      2         2        1    0.686141  3393 x 119863\n",
      "                      2         3        1    0.679759  3295 x 116069\n",
      "                      3         1        1    0.674894  3470 x 125768\n",
      "                      3         2        1    0.671479  3393 x 121161\n",
      "                      3         3        1    0.665462  3295 x 116847\n",
      "              Mean: 0.673757\n",
      "              Std: 0.007065\n",
      "------------------------------------------------------------\n",
      "Trial 15\n",
      "        Model\n",
      "              [Pre@solution]_[Feat@svd100_and_bow_Jun27]_[Model@reg_xgb_linear]\n",
      "        Param\n",
      "              alpha: 0.295\n",
      "              booster: gblinear\n",
      "              eta: 0.86\n",
      "              lambda: 3.75\n",
      "              lambda_bias: 0.7000000000000001\n",
      "              max_evals: 200\n",
      "              nthread: 2\n",
      "              num_round: 290\n",
      "              objective: reg:linear\n",
      "              seed: 2017\n",
      "              silent: 1\n",
      "              task: regression\n",
      "        Result\n",
      "                    Run      Fold      Bag      Kappa      Shape\n",
      "                      1         1        1    0.671441  3470 x 124790\n",
      "                      1         2        1    0.666445  3393 x 125458\n",
      "                      1         3        1    0.662258  3295 x 115835\n",
      "                      2         1        1    0.662826  3470 x 126995\n",
      "                      2         2        1    0.677551  3393 x 119863\n",
      "                      2         3        1    0.668827  3295 x 116069\n",
      "                      3         1        1    0.674271  3470 x 125768\n",
      "                      3         2        1    0.674719  3393 x 121161\n",
      "                      3         3        1    0.656113  3295 x 116847\n",
      "              Mean: 0.668272\n",
      "              Std: 0.006591\n",
      "------------------------------------------------------------\n",
      "Trial 16\n",
      "        Model\n",
      "              [Pre@solution]_[Feat@svd100_and_bow_Jun27]_[Model@reg_xgb_linear]\n",
      "        Param\n",
      "              alpha: 0.06\n",
      "              booster: gblinear\n",
      "              eta: 0.66\n",
      "              lambda: 2.95\n",
      "              lambda_bias: 0.5\n",
      "              max_evals: 200\n",
      "              nthread: 2\n",
      "              num_round: 270\n",
      "              objective: reg:linear\n",
      "              seed: 2017\n",
      "              silent: 1\n",
      "              task: regression\n",
      "        Result\n",
      "                    Run      Fold      Bag      Kappa      Shape\n",
      "                      1         1        1    0.681413  3470 x 124790\n",
      "                      1         2        1    0.676838  3393 x 125458\n",
      "                      1         3        1    0.670486  3295 x 115835\n",
      "                      2         1        1    0.673263  3470 x 126995\n",
      "                      2         2        1    0.687369  3393 x 119863\n",
      "                      2         3        1    0.682493  3295 x 116069\n",
      "                      3         1        1     0.68331  3470 x 125768\n",
      "                      3         2        1    0.680429  3393 x 121161\n",
      "                      3         3        1    0.665613  3295 x 116847\n",
      "              Mean: 0.677913\n",
      "              Std: 0.006560\n",
      "------------------------------------------------------------\n",
      "Trial 17\n",
      "        Model\n",
      "              [Pre@solution]_[Feat@svd100_and_bow_Jun27]_[Model@reg_xgb_linear]\n",
      "        Param\n",
      "              alpha: 0.28\n",
      "              booster: gblinear\n",
      "              eta: 0.5700000000000001\n",
      "              lambda: 4.45\n",
      "              lambda_bias: 2.8000000000000003\n",
      "              max_evals: 200\n",
      "              nthread: 2\n",
      "              num_round: 450\n",
      "              objective: reg:linear\n",
      "              seed: 2017\n",
      "              silent: 1\n",
      "              task: regression\n",
      "        Result\n",
      "                    Run      Fold      Bag      Kappa      Shape\n",
      "                      1         1        1    0.670817  3470 x 124790\n",
      "                      1         2        1    0.662777  3393 x 125458\n",
      "                      1         3        1    0.660734  3295 x 115835\n",
      "                      2         1        1    0.663605  3470 x 126995\n",
      "                      2         2        1    0.675557  3393 x 119863\n",
      "                      2         3        1    0.667156  3295 x 116069\n",
      "                      3         1        1     0.67318  3470 x 125768\n",
      "                      3         2        1    0.671016  3393 x 121161\n",
      "                      3         3        1    0.654454  3295 x 116847\n",
      "              Mean: 0.666588\n",
      "              Std: 0.006383\n",
      "------------------------------------------------------------\n",
      "Trial 18\n",
      "        Model\n",
      "              [Pre@solution]_[Feat@svd100_and_bow_Jun27]_[Model@reg_xgb_linear]\n",
      "        Param\n",
      "              alpha: 0.375\n",
      "              booster: gblinear\n",
      "              eta: 0.9\n",
      "              lambda: 2.35\n",
      "              lambda_bias: 1.0\n",
      "              max_evals: 200\n",
      "              nthread: 2\n",
      "              num_round: 410\n",
      "              objective: reg:linear\n",
      "              seed: 2017\n",
      "              silent: 1\n",
      "              task: regression\n",
      "        Result\n",
      "                    Run      Fold      Bag      Kappa      Shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      1         1        1    0.670817  3470 x 124790\n",
      "                      1         2        1     0.66614  3393 x 125458\n",
      "                      1         3        1    0.662563  3295 x 115835\n",
      "                      2         1        1    0.664228  3470 x 126995\n",
      "                      2         2        1    0.678625  3393 x 119863\n",
      "                      2         3        1    0.666853  3295 x 116069\n",
      "                      3         1        1    0.672401  3470 x 125768\n",
      "                      3         2        1    0.673022  3393 x 121161\n",
      "                      3         3        1    0.658525  3295 x 116847\n",
      "              Mean: 0.668130\n",
      "              Std: 0.005808\n",
      "------------------------------------------------------------\n",
      "Trial 19\n",
      "        Model\n",
      "              [Pre@solution]_[Feat@svd100_and_bow_Jun27]_[Model@reg_xgb_linear]\n",
      "        Param\n",
      "              alpha: 0.28500000000000003\n",
      "              booster: gblinear\n",
      "              eta: 0.05\n",
      "              lambda: 1.5\n",
      "              lambda_bias: 0.1\n",
      "              max_evals: 200\n",
      "              nthread: 2\n",
      "              num_round: 390\n",
      "              objective: reg:linear\n",
      "              seed: 2017\n",
      "              silent: 1\n",
      "              task: regression\n",
      "        Result\n",
      "                    Run      Fold      Bag      Kappa      Shape\n",
      "                      1         1        1    0.676739  3470 x 124790\n",
      "                      1         2        1    0.663389  3393 x 125458\n",
      "                      1         3        1    0.664849  3295 x 115835\n",
      "                      2         1        1    0.668589  3470 x 126995\n",
      "                      2         2        1    0.686141  3393 x 119863\n",
      "                      2         3        1    0.670649  3295 x 116069\n",
      "                      3         1        1    0.673647  3470 x 125768\n",
      "                      3         2        1    0.674411  3393 x 121161\n",
      "                      3         3        1    0.665462  3295 x 116847\n",
      "              Mean: 0.671542\n",
      "              Std: 0.006754\n",
      "------------------------------------------------------------\n",
      "Trial 20\n",
      "        Model\n",
      "              [Pre@solution]_[Feat@svd100_and_bow_Jun27]_[Model@reg_xgb_linear]\n",
      "        Param\n",
      "              alpha: 0.46\n",
      "              booster: gblinear\n",
      "              eta: 0.27\n",
      "              lambda: 1.4000000000000001\n",
      "              lambda_bias: 0.4\n",
      "              max_evals: 200\n",
      "              nthread: 2\n",
      "              num_round: 10\n",
      "              objective: reg:linear\n",
      "              seed: 2017\n",
      "              silent: 1\n",
      "              task: regression\n",
      "        Result\n",
      "                    Run      Fold      Bag      Kappa      Shape\n",
      "                      1         1        1    0.651806  3470 x 124790\n",
      "                      1         2        1    0.646272  3393 x 125458\n",
      "                      1         3        1    0.639706  3295 x 115835\n",
      "                      2         1        1    0.643665  3470 x 126995\n",
      "                      2         2        1    0.655768  3393 x 119863\n",
      "                      2         3        1    0.644835  3295 x 116069\n",
      "                      3         1        1    0.655569  3470 x 125768\n",
      "                      3         2        1    0.644475  3393 x 121161\n",
      "                      3         3        1    0.651438  3295 x 116847\n",
      "              Mean: 0.648171\n",
      "              Std: 0.005340\n",
      "------------------------------------------------------------\n",
      "Trial 21\n",
      "        Model\n",
      "              [Pre@solution]_[Feat@svd100_and_bow_Jun27]_[Model@reg_xgb_linear]\n",
      "        Param\n",
      "              alpha: 0.065\n",
      "              booster: gblinear\n",
      "              eta: 0.75\n",
      "              lambda: 0.45\n",
      "              lambda_bias: 1.4000000000000001\n",
      "              max_evals: 200\n",
      "              nthread: 2\n",
      "              num_round: 350\n",
      "              objective: reg:linear\n",
      "              seed: 2017\n",
      "              silent: 1\n",
      "              task: regression\n",
      "        Result\n",
      "                    Run      Fold      Bag      Kappa      Shape\n",
      "                      1         1        1    0.667389  3470 x 124790\n",
      "                      1         2        1    0.655289  3393 x 125458\n",
      "                      1         3        1    0.659668  3295 x 115835\n",
      "                      2         1        1     0.65566  3470 x 126995\n",
      "                      2         2        1    0.672029  3393 x 119863\n",
      "                      2         3        1    0.676874  3295 x 116069\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-45855a9d9fb1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mobjective\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mhyperopt_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeat_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeat_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m best_params = fmin(objective, param_space, algo=tpe.suggest,\n\u001b[0;32m----> 8\u001b[0;31m                            trials=trials, max_evals=param_space[\"max_evals\"])\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;31m# for f in int_feat:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#     if best_params.has_key(f):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/wc/hyperopt/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin)\u001b[0m\n\u001b[1;32m    305\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m             \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_argmin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m         )\n\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/wc/hyperopt/hyperopt/base.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(self, fn, space, algo, max_evals, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin)\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0mpass_expr_memo_ctrl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpass_expr_memo_ctrl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m             return_argmin=return_argmin)\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/wc/hyperopt/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin)\u001b[0m\n\u001b[1;32m    318\u001b[0m                     verbose=verbose)\n\u001b[1;32m    319\u001b[0m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/wc/hyperopt/hyperopt/fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/wc/hyperopt/hyperopt/fmin.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                 \u001b[0;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstopped\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/wc/hyperopt/hyperopt/fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'job exception: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/wc/hyperopt/hyperopt/base.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[1;32m    838\u001b[0m                 \u001b[0mmemo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m                 print_node_on_error=self.rec_eval_print_node_on_error)\n\u001b[0;32m--> 840\u001b[0;31m             \u001b[0mrval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-45855a9d9fb1>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(p)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrial_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mobjective\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mhyperopt_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeat_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeat_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m best_params = fmin(objective, param_space, algo=tpe.suggest,\n\u001b[1;32m      8\u001b[0m                            trials=trials, max_evals=param_space[\"max_evals\"])\n",
      "\u001b[0;32m<ipython-input-11-aa972b4fd461>\u001b[0m in \u001b[0;36mhyperopt_wrapper\u001b[0;34m(param, feat_folder, feat_name)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m## evaluate performance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m## 关键是这一步骤\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mkappa_cv_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkappa_cv_std\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhyperopt_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeat_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeat_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial_counter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;31m## log\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-6a7d1ef50599>\u001b[0m in \u001b[0;36mhyperopt_obj\u001b[0;34m(param, feat_folder, feat_name, trial_counter)\u001b[0m\n\u001b[1;32m     87\u001b[0m                         \u001b[0mwatchlist\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain_base\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdvalid_base\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'valid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;31m## regression & pairwise ranking with xgboost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                 \u001b[0mbst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain_base\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'num_round'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwatchlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevalerror_regrank_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m                 \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdvalid_base\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0;31m## weighted averageing over different models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/wc/anaconda3/envs/wc/lib/python3.6/site-packages/xgboost-0.6-py3.6.egg/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    202\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/wc/anaconda3/envs/wc/lib/python3.6/site-packages/xgboost-0.6-py3.6.egg/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/wc/anaconda3/envs/wc/lib/python3.6/site-packages/xgboost-0.6-py3.6.egg/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m    894\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[0;32m--> 896\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m    897\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"************************************************************\")\n",
    "print(\"Search for the best params\")\n",
    "#global trial_counter\n",
    "trial_counter = 0\n",
    "trials = Trials()\n",
    "objective = lambda p: hyperopt_wrapper(p, feat_folder, feat_name)\n",
    "best_params = fmin(objective, param_space, algo=tpe.suggest,\n",
    "                           trials=trials, max_evals=param_space[\"max_evals\"])\n",
    "# for f in int_feat:\n",
    "#     if best_params.has_key(f):\n",
    "#         best_params[f] = int(best_params[f])\n",
    "# print(\"************************************************************\")\n",
    "# print(\"Best params\")\n",
    "# for k,v in best_params.items():\n",
    "#     print(\"        %s: %s\" % (k,v))\n",
    "# trial_kappas = -np.asarray(trials.losses(), dtype=float)\n",
    "# best_kappa_mean = max(trial_kappas)\n",
    "# ind = np.where(trial_kappas == best_kappa_mean)[0][0]\n",
    "# best_kappa_std = trials.trial_attachments(trials.trials[ind])['std']\n",
    "# print(\"Kappa stats\")\n",
    "# print(\"        Mean: %.6f\\n        Std: %.6f\" % (best_kappa_mean, best_kappa_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
